{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Parameter Tuning\n",
    "In this notebook, I tune the hyperparameters for a random forest and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ExtractedFinalDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the bad features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_features = []\n",
    "for i in range(8):\n",
    "    langevin = str(i) + \"__max_langevin_fixed_point__m_3__r_30\"\n",
    "    bad_features.append(langevin)\n",
    "    for j in range(9):\n",
    "        quantile = (j+1)*0.1\n",
    "        if quantile != 0.5:\n",
    "            feature_name = str(i) + \"__index_mass_quantile__q_\" + str(quantile)\n",
    "            bad_features.append(feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data, add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(bad_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index = df['9']\n",
    "df = df.drop(['9'], axis=1)\n",
    "df['Label'] = \"One\"\n",
    "df['Label'][2001.0 <= df.index ] = \"Two\"\n",
    "df['Label'][4001.0 <= df.index ] = \"Three\"\n",
    "df['Label'][6001.0 <= df.index ] = \"Four\"\n",
    "df['Label'][8001.0 <= df.index ] = \"Five\"\n",
    "df['Label'][10001.0 <= df.index ] = \"Six\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.map(lambda t: str(t))\n",
    "df = df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_features = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a subsample of 5% of the dataset to do initial parameter tuning on, and create train/validation splits for the subsample and the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 1705)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample = extracted_features.sample(frac=0.05).reset_index(drop=True)\n",
    "subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = subsample.drop(['Label'], 1)\n",
    "y = subsample['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullset = extracted_features.sample(frac=1).reset_index(drop=True)\n",
    "X = fullset.drop(['Label'], 1)\n",
    "y = fullset['Label']\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest grid search. Can use full dataset since random forests are fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.823692992214\n",
      "{'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_jobs': [7, 10, 12],\n",
    "             'n_estimators': [10, 100, 50],\n",
    "             'min_samples_split': [0.2, 0.5, 0.7, 2]}\n",
    "model = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "print 'Training accuracy:', model.score(np.array(X_train_full),np.array(y_train_full))\n",
    "print 'Test accuracy:', model.score(np.array(X_test_full), np.array(y_test_full))\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems as if more estimators might perform better. Try another grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.823414905451\n",
      "{'min_samples_split': 2, 'n_estimators': 300, 'n_jobs': 12}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_jobs': [7, 10, 12],\n",
    "             'n_estimators': [100, 200, 300],\n",
    "             'min_samples_split': [0.2, 0.5, 0.7, 2]}\n",
    "model = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "print 'Training accuracy:', model.score(np.array(X_train_full),np.array(y_train_full))\n",
    "print 'Test accuracy:', model.score(np.array(X_test_full), np.array(y_test_full))\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems as if we're doing about as good as we can using these parameters. Try one more search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.835650723026\n",
      "{'n_estimators': 1000, 'n_jobs': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_jobs': [10, 12, 15, 20],\n",
    "             'n_estimators': [100, 300, 500, 1000]}\n",
    "model = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "print 'Training accuracy:', model.score(np.array(X_train_full),np.array(y_train_full))\n",
    "print 'Test accuracy:', model.score(np.array(X_test_full), np.array(y_test_full))\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly more estimators is better, as makes intuitive sense, but takes longer to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.836484983315\n",
      "{'n_estimators': 4000, 'n_jobs': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_jobs': [10, 12],\n",
    "             'n_estimators': [2000, 4000]}\n",
    "model = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "print 'Training accuracy:', model.score(np.array(X_train_full),np.array(y_train_full))\n",
    "print 'Test accuracy:', model.score(np.array(X_test_full), np.array(y_test_full))\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's apparent that we've plateaued with the number of estimators. Let's train a model on the whole dataset, and save it. Only going to use 1000 estimates since it will be much faster for barely any increase in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestrandomforest.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = RandomForestClassifier(n_jobs = 10, n_estimators = 1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "joblib.dump(model, 'bestrandomforest.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
